"""
ä¸Šæ¸¸ HTTP å®¢æˆ·ç«¯å°è£… - ä¿®å¤ç‰ˆ
"""
import httpx
import json
import gzip
from typing import Optional, Dict, Any, AsyncIterator
from fastapi.responses import StreamingResponse, JSONResponse
from ai_proxy.utils.memory_guard import check_container
from ai_proxy.proxy.stream_checker import StreamChecker, check_response_content
import asyncio

# å…¨å±€ HTTP å®¢æˆ·ç«¯æ± ï¼ˆæ¯ä¸ª base_url ä¸€ä¸ªå®¢æˆ·ç«¯ï¼‰
_client_pool: Dict[str, httpx.AsyncClient] = {}


def get_or_create_client(base_url: str) -> httpx.AsyncClient:
    """èŽ·å–æˆ–åˆ›å»º HTTP å®¢æˆ·ç«¯ï¼ˆå¤ç”¨è¿žæŽ¥æ± ï¼‰"""
    if base_url not in _client_pool:
        _client_pool[base_url] = httpx.AsyncClient(
            timeout=60.0,
            limits=httpx.Limits(
                max_keepalive_connections=20,
                max_connections=100,
                keepalive_expiry=30.0
            )
        )
    
    # å®šæœŸæ£€æŸ¥å®¢æˆ·ç«¯æ± 
    check_container(_client_pool, "http_client_pool")
    
    return _client_pool[base_url]


async def cleanup_clients():
    """æ¸…ç†æ‰€æœ‰å®¢æˆ·ç«¯ï¼ˆåº”ç”¨å…³é—­æ—¶è°ƒç”¨ï¼‰"""
    for client in _client_pool.values():
        await client.aclose()
    _client_pool.clear()


class UpstreamClient:
    """ä¸Šæ¸¸æœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url.rstrip("/")
        self.client = get_or_create_client(self.base_url)  # âœ… å¤ç”¨å®¢æˆ·ç«¯
    
    async def forward_request(
        self,
        method: str,
        path: str,
        headers: Dict[str, str],
        body: Optional[Dict[str, Any]] = None,
        is_stream: bool = False,
        src_format: Optional[str] = None,
        target_format: Optional[str] = None,
        delay_stream_header: bool = False
    ):
        """
        è½¬å‘è¯·æ±‚åˆ°ä¸Šæ¸¸
        
        Args:
            src_format: å®¢æˆ·ç«¯åŽŸå§‹æ ¼å¼ï¼ˆç”¨äºŽå“åº”è½¬æ¢ï¼‰
            target_format: ä¸Šæ¸¸APIæ ¼å¼ï¼ˆå“åº”éœ€è¦ä»Žæ­¤æ ¼å¼è½¬æ¢å›ž src_formatï¼‰
            delay_stream_header: æ˜¯å¦å»¶è¿Ÿå‘é€æµå¼å“åº”å¤´ï¼ˆç›´åˆ°å†…å®¹>2charsæˆ–æœ‰å·¥å…·è°ƒç”¨ï¼‰
        """
        # è¿‡æ»¤æŽ‰ä¸éœ€è¦çš„å¤´ï¼Œå¹¶ç§»é™¤ Accept-Encoding
        filtered_headers = {
            k: v for k, v in headers.items()
            if k.lower() not in ["host", "content-length", "accept-encoding"]
        }
        # æ˜Žç¡®ç¦æ­¢åŽ‹ç¼©ï¼Œé¿å…ç¼–ç é—®é¢˜
        filtered_headers["Accept-Encoding"] = "identity"
        print(f"[UPSTREAM] Request headers: {filtered_headers}")
        
        url = f"{self.base_url}{path}"
        
        # ðŸ”¥ å¼ºåˆ¶ä¸º Gemini æµå¼è¯·æ±‚æ·»åŠ  alt=sse å‚æ•°
        if target_format == "gemini_chat" and is_stream and "streamGenerateContent" in path:
            if "alt=sse" not in url:
                separator = "&" if "?" in url else "?"
                url = f"{url}{separator}alt=sse"
                print(f"[UPSTREAM] âœ… Added alt=sse parameter for Gemini streaming: {url}")
        
        try:
            if is_stream:
                # æµå¼è¯·æ±‚ - ä½¿ç”¨æ‰‹åŠ¨è¯·æ±‚ç®¡ç†ä»¥æ”¯æŒå»¶è¿Ÿå“åº”å¤´
                req = self.client.build_request(
                    method,
                    url,
                    headers=filtered_headers,
                    json=body
                )
                
                response = await self.client.send(req, stream=True)
                
                # æ‰“å°ä¸Šæ¸¸å“åº”å¤´ä¿¡æ¯
                print(f"[UPSTREAM] Upstream response status: {response.status_code}")
                print(f"[UPSTREAM] Upstream response headers: {dict(response.headers)}")
                print(f"[UPSTREAM] Upstream Content-Type: {response.headers.get('content-type', 'None')}")
                print(f"[UPSTREAM] Upstream Content-Encoding: {response.headers.get('content-encoding', 'None')}")
                
                if response.status_code != 200:
                    await response.aclose()
                    # éž 200ï¼Œè¯»å– body å¹¶è¿”å›ž JSONResponse
                    err_body = await response.aread()
                    try:
                        content = json.loads(err_body)
                    except:
                        content = {"error": err_body.decode('utf-8', errors='ignore')}
                    return JSONResponse(status_code=response.status_code, content=content)

                # å¯ç”¨å»¶è¿Ÿæ£€æŸ¥
                if delay_stream_header:
                    print(f"[UPSTREAM] delay_stream_header enabled, target_format={target_format}")
                    checker = StreamChecker(target_format or "openai_chat")
                    buffer = []
                    valid = False
                    chunk_count = 0
                    
                    try:
                        # åˆ›å»ºè¿­ä»£å™¨
                        aiter = response.aiter_bytes()
                        
                        print(f"[UPSTREAM] Starting stream pre-read loop... {target_format}")
                        # é¢„è¯»å¾ªçŽ¯ - ä½¿ç”¨è¿­ä»£å™¨
                        while True:
                            try:
                                chunk = await aiter.__anext__()
                                chunk_count += 1
                                print(f"[UPSTREAM] Received chunk #{chunk_count}, size={len(chunk)}")
                                
                                # æ‰“å° chunk çš„å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰
                                try:
                                    chunk_text = chunk.decode('utf-8')
                                    print(f"[UPSTREAM] Chunk content: {chunk_text[:500]}")
                                except:
                                    print(f"[UPSTREAM] Chunk raw bytes: {chunk[:100]}")
                                
                                buffer.append(chunk)
                                
                                check_result = checker.check_chunk(chunk)
                                print(f"[UPSTREAM] check_chunk returned: {check_result}")
                                
                                if check_result:
                                    valid = True
                                    print(f"[UPSTREAM] Stream validation passed after {chunk_count} chunks, total_bytes={sum(len(b) for b in buffer)}")
                                    break
                                
                                # ä¿æŠ¤æ€§é™åˆ¶ï¼šå¦‚æžœè¶…è¿‡ 1KB è¿˜æ²¡æ»¡è¶³æ¡ä»¶ï¼Œå¼ºåˆ¶æ”¾è¡Œ
                                current_size = sum(len(b) for b in buffer)
                                if current_size > 1048:
                                    print(f"[UPSTREAM] Protection limit: forcing pass after {current_size} bytes in {chunk_count} chunks")
                                    valid = True # è§†ä¸ºé€šè¿‡ï¼Œé¿å…ä¸€ç›´å¡ä½
                                    break
                            except StopAsyncIteration:
                                print(f"[UPSTREAM] Stream ended during pre-read")
                                break
                        
                        print(f"[UPSTREAM] Stream pre-read loop ended: valid={valid}, chunk_count={chunk_count}, total_bytes={sum(len(b) for b in buffer)}")
                        
                        # å¦‚æžœå¾ªçŽ¯ç»“æŸï¼ˆæµç»“æŸäº†ï¼‰è¿˜æ²¡æœ‰ validï¼Œæ£€æŸ¥ä¸€ä¸‹
                        # æ­¤æ—¶ valid ä»ä¸º Falseï¼Œbuffer åŒ…å«æ‰€æœ‰æ•°æ®
                        if not valid:
                            # æ£€æŸ¥ buffer æ˜¯å¦ä¸ºç©ºæˆ–å†…å®¹ä¸è¶³
                            total_bytes = sum(len(b) for b in buffer)
                            if total_bytes == 0:
                                # å®Œå…¨æ²¡æœ‰æŽ¥æ”¶åˆ°ä»»ä½•æ•°æ®
                                print(f"[UPSTREAM] ERROR: Stream ended without any content")
                                raise Exception("Stream ended without any content")
                            else:
                                # æŽ¥æ”¶åˆ°äº†æ•°æ®ä½†ä¸æ»¡è¶³éªŒè¯æ¡ä»¶ï¼ˆå†…å®¹å¤ªå°‘æˆ–æ ¼å¼ä¸å¯¹ï¼‰
                                print(f"[UPSTREAM] ERROR: Stream validation failed after receiving {total_bytes} bytes in {chunk_count} chunks")
                                raise Exception(f"Stream content validation failed: received {total_bytes} bytes but content is insufficient, debug:{buffer.__repr__()}")
                            
                    except Exception as e:
                        print(f"[UPSTREAM] STREAM_PRE_READ_ERROR: {e}")
                        import traceback
                        traceback.print_exc()
                        await response.aclose()
                        return JSONResponse(
                            status_code=502,
                            content={"error": {"code": "UPSTREAM_STREAM_ERROR", "message": f"Stream disconnected before valid content: {str(e)}"}}
                        )

                    # æž„é€ æ–°çš„ç”Ÿæˆå™¨ï¼Œå…ˆå‘ bufferï¼Œå†å‘å‰©ä½™æµ
                    print(f"[UPSTREAM] Creating combined generator with {len(buffer)} buffered chunks")
                    print(f"[UPSTREAM] Buffer content preview: {buffer[0][:200] if buffer else 'empty'}")
                    
                    # ðŸ”¥ SSE æ ¼å¼ä¸éœ€è¦ gzip åŽ‹ç¼©ï¼ˆHTTP å±‚é¢ä¼šè‡ªåŠ¨å¤„ç†ï¼‰
                    use_gzip = False
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æµå¼å“åº”è½¬æ¢
                    if src_format and target_format and src_format != target_format:
                        print(f"[UPSTREAM] Stream response transform enabled: {target_format} -> {src_format}")
                        combined_gen = self._create_combined_generator_with_transform(
                            buffer, aiter, response, target_format, src_format, use_gzip
                        )
                    else:
                        print(f"[UPSTREAM] No stream response transform needed")
                        combined_gen = self._create_combined_generator(buffer, aiter, response, use_gzip)

                    print(f"[UPSTREAM] All response headers: {dict(response.headers)}")
                    
                    # æž„å»ºè¦ä¼ é€’çš„å“åº”å¤´
                    filtered_header_names = [
                        "content-length", "transfer-encoding", "content-encoding",
                        "set-cookie",
                        "strict-transport-security",
                        "content-security-policy", "content-security-policy-report-only",
                        "x-frame-options",
                        "x-content-type-options",
                        "x-xss-protection",
                        "permissions-policy",
                        "referrer-policy",
                    ]
                    pass_headers = {k: v for k, v in response.headers.items()
                                   if k.lower() not in filtered_header_names}
                    
                    # ðŸ”¥ ç¡®ä¿ Gemini SSE æ ¼å¼çš„ Content-Type æ­£ç¡®
                    # ä½¿ç”¨ alt=sse å‚æ•°åŽï¼Œä¸Šæ¸¸åº”è¯¥è¿”å›ž text/event-stream
                    if target_format == "gemini_chat":
                        if pass_headers.get("content-type") != "text/event-stream":
                            print(f"[UPSTREAM] âš ï¸  Setting Content-Type to text/event-stream for Gemini SSE format")
                            pass_headers["content-type"] = "text/event-stream"
                        else:
                            print(f"[UPSTREAM] âœ… Content-Type is already text/event-stream")
                    
                    print(f"[UPSTREAM] Passing headers (after filtering): {pass_headers}")
                    
                    streaming_resp = StreamingResponse(
                        combined_gen,
                        headers=pass_headers
                    )
                    print(f"[UPSTREAM] StreamingResponse object created, returning to caller")
                    return streaming_resp
                
                else:
                    # ä¸å»¶è¿Ÿï¼Œç›´æŽ¥é€ä¼ 
                    filtered_header_names = [
                        "content-length", "transfer-encoding", "content-encoding",
                        "set-cookie",
                        "strict-transport-security",
                        "content-security-policy", "content-security-policy-report-only",
                        "x-frame-options",
                        "x-content-type-options",
                        "x-xss-protection",
                        "permissions-policy",
                        "referrer-policy",
                    ]
                    
                    # å‡†å¤‡å“åº”å¤´
                    pass_headers = {k: v for k, v in response.headers.items()
                                   if k.lower() not in filtered_header_names}
                    
                    # ðŸ”¥ ç¡®ä¿ Gemini SSE æ ¼å¼çš„ Content-Type æ­£ç¡®
                    if target_format == "gemini_chat":
                        if pass_headers.get("content-type") != "text/event-stream":
                            print(f"[UPSTREAM] âš ï¸  Setting Content-Type to text/event-stream for Gemini SSE format")
                            pass_headers["content-type"] = "text/event-stream"
                        else:
                            print(f"[UPSTREAM] âœ… Content-Type is already text/event-stream")
                    
                    return StreamingResponse(
                        response.aiter_bytes(),
                        headers=pass_headers
                    )
            else:
                # éžæµå¼è¯·æ±‚ï¼ˆhttpx ä¼šè‡ªåŠ¨å¤„ç† gzip è§£åŽ‹ï¼‰
                response = await self.client.request(
                    method,
                    url,
                    headers=filtered_headers,
                    json=body
                )
                
                # å°è¯•è§£æž JSON
                try:
                    content = response.json()
                except Exception:
                    # éž JSON å“åº”ï¼Œè¿”å›žæ–‡æœ¬
                    content = {"text": response.text, "status_code": response.status_code}
                
                # å¦‚æžœéœ€è¦å“åº”è½¬æ¢
                if src_format and target_format and src_format != target_format:
                    try:
                        content = self._transform_response(content, target_format, src_format)
                    except Exception as e:
                        print(f"[ERROR] Response transform failed: {e}")
                        import traceback
                        traceback.print_exc()
                        # è½¬æ¢å¤±è´¥æ—¶è¿”å›žåŽŸå§‹å“åº”
                
                # å¦‚æžœå¯ç”¨äº†å†…å®¹æ£€æŸ¥ï¼ˆdelay_stream_header å¯¹éžæµå¼ä¹Ÿç”Ÿæ•ˆï¼‰
                if delay_stream_header and response.status_code == 200:
                    # å¦‚æžœè¿›è¡Œäº†æ ¼å¼è½¬æ¢ï¼Œåº”è¯¥ç”¨è½¬æ¢åŽçš„æ ¼å¼ï¼ˆsrc_formatï¼‰è¿›è¡Œæ£€æŸ¥
                    # å¦åˆ™ç”¨ä¸Šæ¸¸æ ¼å¼ï¼ˆtarget_formatï¼‰è¿›è¡Œæ£€æŸ¥
                    if src_format and target_format and src_format != target_format:
                        check_format = src_format  # ä½¿ç”¨è½¬æ¢åŽçš„æ ¼å¼
                    else:
                        check_format = target_format or "openai_chat"  # ä½¿ç”¨ä¸Šæ¸¸æ ¼å¼
                    passed, error_msg = check_response_content(content, check_format)
                    
                    if not passed:
                        print(f"[CONTENT_CHECK_FAILED] {error_msg}")
                        return JSONResponse(
                            status_code=400,
                            content={
                                "error": {
                                    "code": "EMPTY_RESPONSE",
                                    "message": error_msg,
                                    "type": "content_validation_error"
                                }
                            }
                        )
                
                return JSONResponse(
                    status_code=response.status_code,
                    content=content
                )
        
        except Exception as e:
            return JSONResponse(
                status_code=500,
                content={
                    "error": {
                        "code": "UPSTREAM_ERROR",
                        "message": f"Upstream request failed: {str(e)}",
                        "type": "upstream_error"
                    }
                }
            )
    
    async def _create_combined_generator(
        self,
        buffer: list,
        aiter: AsyncIterator,
        response: httpx.Response,
        use_gzip: bool = False
    ) -> AsyncIterator[bytes]:
        """åˆ›å»ºç»„åˆç”Ÿæˆå™¨ï¼ˆæ— è½¬æ¢ï¼‰"""
        print(f"[UPSTREAM] âš¡ Generator started! (gzip={use_gzip})")
        
        if not use_gzip:
            # ä¸ä½¿ç”¨ gzipï¼Œç›´æŽ¥é€ä¼ 
            try:
                # å…ˆè¾“å‡ºç¼“å†²çš„å†…å®¹
                print(f"[UPSTREAM] Yielding {len(buffer)} buffered chunks")
                for chunk in buffer:
                    yield chunk
                
                # ç»§ç»­ä»Žè¿­ä»£å™¨è¯»å–å‰©ä½™å†…å®¹
                print(f"[UPSTREAM] Continuing with remaining stream...")
                try:
                    while True:
                        chunk = await aiter.__anext__()
                        yield chunk
                except StopAsyncIteration:
                    print(f"[UPSTREAM] Stream completed")
            except Exception as e:
                print(f"[UPSTREAM] âŒ Generator exception: {e}")
                import traceback
                traceback.print_exc()
                raise
            finally:
                print(f"[UPSTREAM] Closing response connection")
                await response.aclose()
        else:
            # ä½¿ç”¨ gzip åŽ‹ç¼©
            try:
                # åˆ›å»ºåŽ‹ç¼©å¯¹è±¡
                import zlib
                compressor = zlib.compressobj(
                    level=6,
                    method=zlib.DEFLATED,
                    wbits=zlib.MAX_WBITS | 16  # 16 = gzip æ ¼å¼
                )
                
                # å…ˆåŽ‹ç¼©ç¼“å†²çš„å†…å®¹
                print(f"[UPSTREAM] Compressing {len(buffer)} buffered chunks with gzip")
                for chunk in buffer:
                    compressed = compressor.compress(chunk)
                    if compressed:
                        yield compressed
                
                # ç»§ç»­åŽ‹ç¼©å‰©ä½™æµ
                print(f"[UPSTREAM] Continuing with remaining stream (compressed)...")
                try:
                    while True:
                        chunk = await aiter.__anext__()
                        compressed = compressor.compress(chunk)
                        if compressed:
                            yield compressed
                except StopAsyncIteration:
                    print(f"[UPSTREAM] Stream completed, flushing compressor")
                
                # åˆ·æ–°åŽ‹ç¼©å™¨ï¼Œè¾“å‡ºå‰©ä½™æ•°æ®
                final_compressed = compressor.flush()
                if final_compressed:
                    yield final_compressed
                    
            except Exception as e:
                print(f"[UPSTREAM] âŒ Generator exception: {e}")
                import traceback
                traceback.print_exc()
                raise
            finally:
                print(f"[UPSTREAM] Closing response connection")
                await response.aclose()
    
    async def _create_combined_generator_with_transform(
        self,
        buffer: list,
        aiter: AsyncIterator,
        response: httpx.Response,
        from_format: str,
        to_format: str,
        use_gzip: bool = False
    ) -> AsyncIterator[bytes]:
        """åˆ›å»ºç»„åˆç”Ÿæˆå™¨ï¼ˆå¸¦æ ¼å¼è½¬æ¢ï¼‰- æš‚æ—¶é€ä¼ """
        print(f"[UPSTREAM] âš¡ Transform generator started: {from_format} -> {to_format} (gzip={use_gzip})")
        print(f"[UPSTREAM] Note: Stream response transform is not yet fully implemented, falling back to passthrough")
        
        # æš‚æ—¶ç›´æŽ¥è°ƒç”¨æ— è½¬æ¢ç‰ˆæœ¬
        async for chunk in self._create_combined_generator(buffer, aiter, response, use_gzip):
            yield chunk
    
    def _transform_response(
        self,
        response: Dict[str, Any],
        from_format: str,
        to_format: str
    ) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸Šæ¸¸å“åº”æ ¼å¼
        
        Args:
            response: ä¸Šæ¸¸å“åº”ï¼ˆfrom_format æ ¼å¼ï¼‰
            from_format: ä¸Šæ¸¸APIæ ¼å¼
            to_format: å®¢æˆ·ç«¯æœŸæœ›æ ¼å¼
        """
        from ai_proxy.transform.formats.parser import get_parser
        
        # èŽ·å–è§£æžå™¨
        from_parser = get_parser(from_format)
        to_parser = get_parser(to_format)
        
        if not from_parser or not to_parser:
            print(f"[WARN] Parser not found: from={from_format}, to={to_format}")
            return response
        
        # è½¬æ¢ï¼šä¸Šæ¸¸æ ¼å¼ -> å†…éƒ¨æ ¼å¼ -> å®¢æˆ·ç«¯æ ¼å¼
        try:
            internal_resp = from_parser.resp_to_internal(response)
            client_resp = to_parser.internal_to_resp(internal_resp)
            print(f"[DEBUG] Response transformed: {from_format} -> {to_format}")
            return client_resp
        except Exception as e:
            print(f"[ERROR] Response transform exception: {e}")
            raise